<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nlugon.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nlugon.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-30T01:58:34+00:00</updated><id>https://nlugon.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Ground Radar and ADS-B for BVLOS operations</title><link href="https://nlugon.github.io/blog/2025/Radar-ADSB/" rel="alternate" type="text/html" title="Ground Radar and ADS-B for BVLOS operations"/><published>2025-06-28T08:00:00+00:00</published><updated>2025-06-28T08:00:00+00:00</updated><id>https://nlugon.github.io/blog/2025/Radar-ADSB</id><content type="html" xml:base="https://nlugon.github.io/blog/2025/Radar-ADSB/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HiddenLevel-480.webp 480w,/assets/img/HiddenLevel-800.webp 800w,/assets/img/HiddenLevel-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/HiddenLevel.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="HiddenLevel-RadarAndADSB" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Overlay of radar detections (V shapes) and ADS-B tracks (aircraft shapes). Credits: Hidden Level</p> <p>As <strong>unmanned aerial systems (UAS)</strong> expand into <strong>Beyond Visual Line of Sight (BVLOS)</strong> missions, whether for drone deliveries, infrastructure inspection, or emergency response, ensuring <strong>full airspace awareness</strong> becomes mission-critical. One project I worked on tackled this challenge by comparing data from a ground-based radar with ADS-B (Automatic Dependent Surveillance–Broadcast), with the goal of assessing the radar’s tracking accuracy as part of a redundant airspace surveillance system, which would strengthen the situational awareness needed for autonomous UAS to complete operations safely.</p> <hr/> <h3 id="what-i-worked-on">What I Worked On</h3> <p>The <strong>high-level objective</strong> of the project was to validate the <strong>accuracy</strong> of a <strong>ground-based radar surveillance system</strong> that integrates with other sensing layers—ADS-B and Remote ID—in order to deliver a full airspace picture to BVLOS drone operations. This system aims to ensure that autonomous drones can operate safely, even in environments with mixed or unreliable signal availability.</p> <p><strong>At my level</strong>, my focus was on <strong>characterizing the accuracy and coverage of the radar</strong>. Using Python, I processed large datasets from both the radar and nearby ADS-B receivers. Main tasks included:</p> <ul> <li><strong>Matching radar and ADS-B tracks</strong> based on timestamp and 3D spatial proximity to evaluate the radar’s positional accuracy.</li> <li><strong>Identifying radar detections</strong> that had <strong>no corresponding ADS-B track</strong>—likely representing non-cooperative aircraft, drones, or possible noisy observations.</li> <li><strong>Determining which ADS-B tracks were not detected</strong> by the radar, potentially due to occlusion, distance, or potential other factors.</li> </ul> <p>Beyond these analyses, I also examined <strong>what environmental and contextual factors</strong> could influence the radar’s performance. By correlating accuracy and detection gaps with <strong>weather data, time of day, and geographical areas</strong>, I aimed to understand the <strong>limitations</strong> and <strong>potential optimization areas for deploying such radar systems</strong>.</p> <hr/> <h3 id="why-we-need-ground-radar">Why We Need Ground Radar</h3> <p>While ADS-B is the dominant method for tracking large aircraft, it’s not without failure modes:</p> <ul> <li>A transponder may malfunction.</li> <li>Certain aircraft—such as military or uncooperative planes—may intentionally fly without broadcasting.</li> <li>Even when functioning, ADS-B reception can be obstructed or interfered with.</li> </ul> <p>Meanwhile, <strong>drones are not allowed to broadcast ADS-B</strong> under FAA Part 107 regulations. Instead, they must comply with <strong>Remote ID</strong> requirements—but Remote ID has its own challenges:</p> <ul> <li>The broadcast range is limited, and its effectiveness over long distances is currently a bit uncertain.</li> <li>Not all drones may comply or would need to comply, in the case of sub 250g drones.</li> <li>Remote ID, like ADS-B, depends on proper functioning hardware and line-of-sight.</li> </ul> <p>Because of these limitations, <strong>relying solely on ADS-B and Remote ID is not enough</strong>. This is where <strong>ground radar adds essential redundancy</strong>. It doesn’t depend on broadcast cooperation, and is capable of detecting flying objects within line-of-sight—whether cooperative or untracked. This redundancy is valuable not only for detecting <strong>uncooperative aircraft</strong>, but also for identifying <strong>low-altitude drones and unknown aerial activity</strong>—critical for safe integration of drones into shared airspace.</p> <hr/> <h3 id="going-further-towards-scalable-and-resilient-bvlos-airspace-awareness">Going Further: Towards Scalable and Resilient BVLOS Airspace Awareness</h3> <p>As drone adoption continues to grow—especially for autonomous and BVLOS operations—the airspace, particularly in and around urban areas, is expected to become more <strong>congested and dynamic</strong>. Ensuring the safety of these operations requires that every autonomous aircraft has access to real-time information about:</p> <ul> <li><strong>Crewed aircraft</strong> via ADS-B</li> <li><strong>Nearby drones</strong> via Remote ID</li> <li><strong>Non-cooperative or unexpected traffic</strong> via radar</li> </ul> <p>No single system is sufficient. A comprehensive solution will depend on <strong>multi-layered sensing architectures</strong>, where radar acts not as a backup but as a <strong>critical redundant layer</strong> alongside broadcast-based systems.</p> <p>To support this, we’ll need:</p> <ul> <li><strong>More ground radars</strong>—strategically positioned to minimize blind zones and maximize coverage</li> <li><strong>Optimized deployment locations</strong>, accounting for terrain, urban clutter, and electromagnetic interference</li> <li><strong>Sensor fusion frameworks</strong> that combine radar, ADS-B, and Remote ID into a <strong>unified airspace picture</strong></li> </ul> <p>However, a key challenge arises: BVLOS drones relying on ground-based surveillance must be able to <strong>receive that data in real time</strong>. If the communication link is lost, the drone loses its situational awareness, creating a safety risk.</p> <p>This leads to an additional sensing level but also important tradeoff:</p> <ul> <li><strong>Ground-based awareness provides long-range, centralized detection</strong>, but introduces communication dependency</li> <li><strong>Onboard sensors</strong> (e.g. lightweight radar, cameras, acoustic or vision-based detect-and-avoid) offer <strong>resilience</strong>, but come with <strong>cost, weight, and power tradeoffs</strong></li> </ul> <p>For maximum safety, <strong>future BVLOS drones should incorporate both</strong>:</p> <ul> <li><strong>Live access to the shared surveillance layer</strong> (ADS-B, Remote ID, ground radar)</li> <li><strong>Local onboard sensing</strong> for additional awareness and collision avoidance</li> </ul> <p>This hybrid approach ensures that even if one layer fails—due to signal loss, sensor occlusion, or equipment malfunction—the drone still retains some level of autonomous awareness, enabling it to react and deconflict.</p> <hr/> <h4 id="image-credits">Image Credits:</h4> <p><a href="https://www.hiddenlevel.com/press/hidden-level-awarded-u-s-air-force-phase-1-sttr-contract">Hidden Level</a></p> <hr/>]]></content><author><name></name></author><category term="aerospace"/><category term="radar"/><category term="adsb"/><category term="drones"/><category term="air-traffic-control"/><category term="systems-engineering"/><summary type="html"><![CDATA[Validating a ground radar's accuracy and its importance for BVLOS drone operations]]></summary></entry><entry><title type="html">Practicing Photogrammetry with Google Earth Studio</title><link href="https://nlugon.github.io/blog/2025/RealityCaptureAndPostshot/" rel="alternate" type="text/html" title="Practicing Photogrammetry with Google Earth Studio"/><published>2025-06-27T10:00:00+00:00</published><updated>2025-06-27T10:00:00+00:00</updated><id>https://nlugon.github.io/blog/2025/RealityCaptureAndPostshot</id><content type="html" xml:base="https://nlugon.github.io/blog/2025/RealityCaptureAndPostshot/"><![CDATA[<p>Recently explored the potential of <strong>Google Earth Studio</strong> as a tool for <strong>planning and previewing drone photogrammetry workflows</strong>. Around the same time, I was interested in creating small 3D-printed models of notable infrastructure at NASA Ames, such as the <strong>NFAC (the world’s largest wind tunnel)</strong>. Since Google Earth already provides detailed 3D terrain and structure data, I thought it would be interesting to test whether Google Earth Studio could serve as a simulation tool for photogrammetry.</p> <p>Getting started was fairly straightforward. After generating a short animation, I used <strong>RealityCapture</strong> to convert the footage into a textured mesh, which I then cleaned up in <strong>Blender</strong> and prepared for 3D printing. As a secondary experiment, I also used <strong>Jawset PostShot</strong> to generate a Gaussian Splat from the same footage. While the splat wasn’t perfect due to limited sky coverage in the animation, the overall results were compelling. Here’s a quick overview of the workflow and results.</p> <hr/> <h4 id="step-1-google-earth-studio--generate-animation">Step 1: Google Earth Studio – Generate Animation</h4> <p><a href="https://www.google.com/earth/studio/">Google Earth Studio</a> is a browser-based animation tool from Google that allows you to create cinematic flyovers of real-world locations. Documentation is available <a href="https://earth.google.com/studio/docs/">here</a>. To access it:</p> <ul> <li>Go to the <a href="https://www.google.com/earth/studio/">Google Earth Studio website</a></li> <li>Click <strong>Try Earth Studio</strong></li> <li>Sign in with a Google account and briefly describe your intended use</li> </ul> <p>I used the spiral orbit template centered on the NFAC. It’s possible to import <code class="language-plaintext highlighter-rouge">.kml</code> files into Earth Studio—though based on my testing, these files only support overlays and paths for visualization within the animation, rather than actual flight control.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/GoogleEarthStudio1-480.webp 480w,/assets/img/GoogleEarthStudio1-800.webp 800w,/assets/img/GoogleEarthStudio1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/GoogleEarthStudio1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Google Earth Studio templates" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Google Earth Studio templates</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/GoogleEarthStudio2-480.webp 480w,/assets/img/GoogleEarthStudio2-800.webp 800w,/assets/img/GoogleEarthStudio2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/GoogleEarthStudio2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Google Earth Studio interface" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Google Earth Studio main interface</p> <p>I exported the rendered animation as an <code class="language-plaintext highlighter-rouge">.mp4</code> file, which could be directly imported into both <strong>RealityCapture</strong> and <strong>PostShot</strong>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnelSpiralShort-480.webp 480w,/assets/img/AmesWindTunnelSpiralShort-800.webp 800w,/assets/img/AmesWindTunnelSpiralShort-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnelSpiralShort.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Google Earth Studio animation over NASA Ames wind tunnel. Attribution: Google Earth, Vexcel Imaging US, Inc." data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Animation flyover of the NFAC at NASA Ames. Attribution: Google Earth, Vexcel Imaging US, Inc.</p> <hr/> <h4 id="step-2-realitycapture--convert-video-to-mesh">Step 2: RealityCapture – Convert Video to Mesh</h4> <p>In <strong>RealityCapture</strong>, I imported the <code class="language-plaintext highlighter-rouge">.mp4</code> and allowed it to extract approximately 200 frames. Using mostly default settings, I ran the photogrammetry pipeline to reconstruct a textured mesh.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnel-RealityCapture-480.webp 480w,/assets/img/AmesWindTunnel-RealityCapture-800.webp 800w,/assets/img/AmesWindTunnel-RealityCapture-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnel-RealityCapture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Photogrammetry result in RealityCapture" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Generated textured mesh from Google Earth Studio footage</p> <p>After reconstruction and simplification, I exported the mesh as a <code class="language-plaintext highlighter-rouge">.obj</code> file for further editing in Blender.</p> <hr/> <h4 id="step-3-blender--mesh-editing">Step 3: Blender – Mesh Editing</h4> <p>Photogrammetry-generated meshes often require cleanup. I used <strong>Blender</strong> to refine the geometry and make adjustments to prepare the model for 3D printing.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnel-Blender2-480.webp 480w,/assets/img/AmesWindTunnel-Blender2-800.webp 800w,/assets/img/AmesWindTunnel-Blender2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnel-Blender2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Editing the photogrammetry mesh in Blender" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Post-processing and cleanup of the mesh in Blender</p> <hr/> <h4 id="step-4-orca-slicer--3d-printing">Step 4: Orca Slicer – 3D Printing</h4> <p>The refined mesh was then imported into <strong>Orca Slicer</strong>, where I set the model size and printing settings.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnel-Orca-480.webp 480w,/assets/img/AmesWindTunnel-Orca-800.webp 800w,/assets/img/AmesWindTunnel-Orca-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnel-Orca.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Preparing the mesh in Orca Slicer" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Slicing the model in Orca Slicer</p> <hr/> <h4 id="step-5--print-results">Step 5 – Print Results</h4> <p>The final 3D print is shown below. The full model is roughly 12 cm across, with the wind tunnel itself clearly recognizable. Some areas could benefit from additional mesh refinement to ensure consistent flatness. Surrounding facilities could be better defined but are in most part still identifiable. One idea for future iterations would be multi-material printing to better distinguish between buildings, roads, and grass areas.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnel-3DPrint-480.webp 480w,/assets/img/AmesWindTunnel-3DPrint-800.webp 800w,/assets/img/AmesWindTunnel-3DPrint-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnel-3DPrint.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="3D Printed Model" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Final result: 3D printed model of the NFAC</p> <hr/> <h4 id="extra-jawset-postshot--gaussian-splatting">Extra: Jawset PostShot – Gaussian Splatting</h4> <p>For comparison, I also processed the video using <strong>Jawset PostShot</strong> to create a <strong>Gaussian Splat</strong>. I used the <em>splat3 radiance field</em> profile and left most settings at default. The tool extracted around 150 images and reconstructed a lightweight splat-based rendering.</p> <p>One benefit of splatting is that it can represent background elements like the sky—something that traditional photogrammetry struggles with due to a lack of trackable features. However, because the animation included limited sky coverage, some regions remained unrepresented.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/AmesWindTunnel-Postshot-480.webp 480w,/assets/img/AmesWindTunnel-Postshot-800.webp 800w,/assets/img/AmesWindTunnel-Postshot-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/AmesWindTunnel-Postshot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gaussian Splat rendering in PostShot" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted text-center mt-2">Gaussian Splat generated from the same animation using PostShot</p> <hr/> <h4 id="final-thoughts">Final Thoughts</h4> <p><strong>Google Earth Studio</strong> is a surprisingly capable tool for generating flyover-style animations, and it integrates well with both <strong>RealityCapture</strong> and <strong>Blender</strong> for experimentation and prototyping. I was able to produce a reasonably accurate physical model of the NFAC, entirely from virtual footage.</p> <p>As a future improvement, it would be useful if Earth Studio supported importing <code class="language-plaintext highlighter-rouge">.kml</code> flight plans for true photogrammetry simulation. Although <code class="language-plaintext highlighter-rouge">.kml</code> overlays are supported, they currently don’t drive the camera directly.</p> <p>Interestingly, the watermark embedded in the rendered video didn’t show up in either the mesh or splat results—likely rejected as noise by both systems.</p> <p>For those without access to drones or physical sites, I recommend exploring freely available photogrammetry datasets such as those hosted by <a href="https://www.esri.com/en-us/arcgis/products/arcgis-reality/resources/sample-drone-datasets">ESRI</a>. They’re a great resource for tuning your reconstruction pipeline before working with your own data.</p> <hr/> <p><strong>Tools Used:</strong></p> <ul> <li><a href="https://www.google.com/earth/studio/">Google Earth Studio</a></li> <li><a href="https://www.capturingreality.com/">RealityCapture (RealityScan)</a></li> <li><a href="https://www.jawset.com">Jawset PostShot</a></li> <li><a href="https://www.blender.org/">Blender</a></li> <li><a href="https://orca-slicer.com">Orca Slicer</a></li> </ul>]]></content><author><name></name></author><category term="graphics"/><category term="photogrammetry"/><category term="gaussian-splatting"/><category term="nasa"/><category term="blender"/><summary type="html"><![CDATA[A quick experiment using Google Earth Studio, RealityCapture, and Jawset PostShot]]></summary></entry><entry><title type="html">Space and Aerospace Websites to Check Out</title><link href="https://nlugon.github.io/blog/2025/cool-websites/" rel="alternate" type="text/html" title="Space and Aerospace Websites to Check Out"/><published>2025-01-25T18:00:00+00:00</published><updated>2025-01-25T18:00:00+00:00</updated><id>https://nlugon.github.io/blog/2025/cool-websites</id><content type="html" xml:base="https://nlugon.github.io/blog/2025/cool-websites/"><![CDATA[<p>Explore this selection of space and aerospace websites, offering tools, insights, and data to inspire and inform your journey through the cosmos.</p> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mars-trek-website-480.webp 480w,/assets/img/mars-trek-website-800.webp 800w,/assets/img/mars-trek-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mars-trek-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://trek.nasa.gov/mars/" target="_blank">NASA Mars Trek</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://trek.nasa.gov/mars/" target="_blank">NASA Mars Trek</a></h3> <p>An interactive mapping tool for Mars exploration, offering a detailed view of the Martian surface with data from multiple missions.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dsn-website-480.webp 480w,/assets/img/dsn-website-800.webp 800w,/assets/img/dsn-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/dsn-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://eyes.nasa.gov/apps/dsn-now/" target="_blank">NASA DSN Now</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://eyes.nasa.gov/apps/dsn-now/" target="_blank">NASA DSN Now</a></h3> <p>Track real-time communication between spacecraft and NASA's Deep Space Network (DSN) antennas worldwide.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nasa-airborne-science-480.webp 480w,/assets/img/nasa-airborne-science-800.webp 800w,/assets/img/nasa-airborne-science-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/nasa-airborne-science.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://airbornescience.nasa.gov/tracker/" target="_blank">NASA Airborne Science Tracker</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://airbornescience.nasa.gov/tracker/" target="_blank">NASA Airborne Science Tracker</a></h3> <p>Follow NASA's airborne science missions in real-time and learn about the aircraft and their research objectives.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rocket-website-480.webp 480w,/assets/img/rocket-website-800.webp 800w,/assets/img/rocket-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/rocket-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://rocketlaunch.org" target="_blank">Rocket Launch Schedule</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://rocketlaunch.org" target="_blank">Rocket Launch Schedule</a></h3> <p>Stay updated on upcoming rocket launches.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/zoom-website-480.webp 480w,/assets/img/zoom-website-800.webp 800w,/assets/img/zoom-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/zoom-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://zoom.earth" target="_blank">Zoom Earth</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://zoom.earth" target="_blank">Zoom Earth</a></h3> <p>Offering near real-time satellite imagery, with a captivating view of global weather patterns, natural disasters, and other planetary phenomena.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/moon-website-480.webp 480w,/assets/img/moon-website-800.webp 800w,/assets/img/moon-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/moon-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://quickmap.lroc.asu.edu/" target="_blank">Lunar QuickMap</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://quickmap.lroc.asu.edu/" target="_blank">Lunar QuickMap</a></h3> <p>A powerful tool for exploring the Moon’s surface, featuring data from NASA's Lunar Reconnaissance Orbiter.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/vfr-website-480.webp 480w,/assets/img/vfr-website-800.webp 800w,/assets/img/vfr-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/vfr-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://vfrmap.com" target="_blank">VFR Map</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://vfrmap.com" target="_blank">VFR Map</a></h3> <p>View detailed aeronautical maps for visual flight rules (VFR).</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/satellite-website-480.webp 480w,/assets/img/satellite-website-800.webp 800w,/assets/img/satellite-website-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/satellite-website.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://geoxc-apps.bd.esri.com/space/satellite-explorer/#" target="_blank">Esri Satellite Explorer</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://geoxc-apps.bd.esri.com/space/satellite-explorer/#" target="_blank">Esri Satellite Explorer</a></h3> <p>Visualize satellite orbits and track their movements in real-time.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/satnogs-480.webp 480w,/assets/img/satnogs-800.webp 800w,/assets/img/satnogs-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/satnogs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://db.satnogs.org" target="_blank">SatNOGS DB</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://db.satnogs.org" target="_blank">SatNOGS DB</a></h3> <p>A global open-source database of satellite transmissions collected by amateur ground stations—browse frequencies, decode signals, and explore satellite metadata.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/leolabs-480.webp 480w,/assets/img/leolabs-800.webp 800w,/assets/img/leolabs-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/leolabs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://platform.leolabs.space/visualization" target="_blank">LeoLabs Visualization Platform</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://platform.leolabs.space/visualization" target="_blank">LeoLabs Visualization Platform</a></h3> <p>Visualize satellites and space debris in low Earth orbit (LEO) in real-time—an essential tool for tracking and monitoring orbital traffic and collisions.</p> </div> </div> <hr/> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/forest-watch2-480.webp 480w,/assets/img/forest-watch2-800.webp 800w,/assets/img/forest-watch2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/forest-watch2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p class="text-muted mt-2" style="font-size: 0.9em;"> Image credit: <a href="https://www.globalforestwatch.org/map/" target="_blank">Global Forest Watch</a> </p> </div> <div class="col-sm mt-3 mt-md-0"> <h3><a href="https://www.globalforestwatch.org/map/" target="_blank">Global Forest Watch</a></h3> <p>Visually engaging and interactive platform to monitor forest changes, deforestation, and fire alerts in real-time, for raising awareness about the impact of wildfires and environmental conservation efforts worldwide.</p> </div> </div>]]></content><author><name></name></author><category term="exploration"/><category term="space"/><category term="aerospace"/><category term="websites"/><summary type="html"><![CDATA[A collection of websites related to space and aerospace.]]></summary></entry><entry><title type="html">Moon and Mars Landings</title><link href="https://nlugon.github.io/blog/2025/geojson/" rel="alternate" type="text/html" title="Moon and Mars Landings"/><published>2025-01-05T12:06:00+00:00</published><updated>2025-01-05T12:06:00+00:00</updated><id>https://nlugon.github.io/blog/2025/geojson</id><content type="html" xml:base="https://nlugon.github.io/blog/2025/geojson/"><![CDATA[<p>Map showing the equivalent locations of Moon and Mars landings. Click on the points for more information.</p> <div id="map" style="height: 500px; width: 100%;"></div> <h2 id="sources">Sources</h2> <ol> <li><a href="https://science.nasa.gov/resource/apollo-landing-sites-with-moon-phases/">Apollo Landing Sites with Moon Phases - NASA</a></li> <li><a href="https://en.wikipedia.org/wiki/List_of_landings_on_extraterrestrial_bodies">List of landings on extraterrestrial bodies - Wikipedia</a></li> </ol>]]></content><author><name></name></author><category term="space-exploration"/><category term="planetary"/><category term="landings"/><category term="geojson"/><category term="maps"/><summary type="html"><![CDATA[Visualizing Moon and Mars Landing Locations.]]></summary></entry></feed>